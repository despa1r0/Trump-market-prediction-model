Отчет по проделанной работе и текущему состоянию проекта
1. Предыстория и проблема
В рамках проекта изначально была выбрана архитектура на основе FinBERT. Было реализовано несколько версий моделей, однако после серии тестов были получены следующие результаты:
* Model v1 — ~20%
* Model v2 — ~15%
* Model v3 — от 22.1% до 36%
Данные результаты являются неудовлетворительными, особенно с учётом того, что:
* они хуже или сопоставимы с базовой логистической регрессией;
* сложность и ресурсоёмкость BERT-моделей не оправдывают такой результат.
Были предприняты попытки улучшения:
* ручной отбор данных,
* фильтрация,
* «бустинг» результатов и точечные эвристики,
но, к сожалению, значимого прироста это не дало.

Приношу извинения за первоначальный выбор слишком тяжёлого решения — BERT оказался неоптимальным для текущей задачи и данных. Новый подход показал себя значительно лучше и стабильнее.
2. Принятое решение
В связи с этим я принял решение отказаться от BERT-подхода в пользу более лёгких и интерпретируемых моделей, которые:
* быстрее обучаются,
* проще в поддержке,
* дают более стабильные результаты на имеющихся данных.
________________


3. Новый проект: что было реализовано
В новом проекте была выстроена полноценная ML-пайплайн архитектура с акцентом на читаемость, тестируемость и соответствие требованиям.
Основные результаты:
* Создан датасет и проведён его анализ
* Реализованы 4 разных модели
* Добавлена инженерия признаков
* Написаны юнит-тесты
* Сделана демо-программа для пользовательского ввода твитов
* Построены графики для сравнения моделей
📈 Текущая точность моделей: 50–60%, что:
* в 2–3 раза лучше, чем предыдущие решения,
* соответствует требованиям проекта,
* показывает более стабильное поведение.
________________


4. Структура проекта и описание файлов
1️⃣ data_loader.py — загрузка и подготовка данных
OOP-класс для работы с датасетом:
* загрузка CSV,
* очистка данных,
* создание целевой переменной,
* подготовка X и y.
________________


2️⃣ exploratory_analysis.py — анализ данных (Wstępna analiza)
* базовая статистика,
* корреляционная матрица,
* распределение классов,
* визуализации (сохранение в PNG).
________________


3️⃣ feature_engineering.py — инженерия признаков
Добавлены дополнительные признаки:
* длина текста,
* sentiment analysis,
* ключевые слова,
* количество заглавных букв,
* пунктуация,
* временные признаки и др.
________________


4️⃣ model_trainer.py — обучение моделей
Реализовано обучение и fine-tuning:
* Logistic Regression
* Naive Bayes
* Random Forest
* Gradient Boosting
Используется GridSearchCV, сохраняется лучшая модель.
________________


5️⃣ model_evaluator.py — оценка моделей
* Classification Report
* Confusion Matrix
* Accuracy, Precision, Recall, F1
* сравнение всех моделей между собой.
________________


6️⃣ test_models.py — unit-тесты
* более 15 тестов,
* покрытие всех ключевых компонентов,
* проверка стабильности пайплайна.
________________


7️⃣ main.py — главный pipeline
* автоматический запуск всего процесса,
* читаемые логи,
* цветной вывод (colorama).
________________




5. Задачи, которые предстоит выполнить
1. Привести в порядок архитектуру проекта
2. Создать отдельную папку для всех графиков
3. Подготовить подробный отчёт по данным
4. Возможно скрестить несколько файлов в один
5. Сделать презентацию по проекту
6. Реализовать полноценное демо:
   * ввод собственных твитов,
   * сравнение ответов разных моделей
________________


Репозиторий на GitHub будет создан до 8 числа.

P.S Забыл добавить что в проекте оставил создание датасета и графики по анализу того самого датасета, находится это в папке: DataPrep and Graphs.

Также в архиве сейчас много разных графиков, вы можете свободно их удалить и заново запустить скрипты и они создаются по новой.